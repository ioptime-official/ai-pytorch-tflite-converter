{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "N4-vpE63NqSH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import onnxruntime\n",
        "import onnx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(img_pth, model):\n",
        "  cls= ['Pizza', 'Steak']\n",
        "  img= cv.imread(img_pth)\n",
        "  img= cv.resize(img, (224, 224))\n",
        "  a= img.transpose(2, 0, 1)\n",
        "  a= np.expand_dims(a, 0)\n",
        "  a= a/255\n",
        "  a= torch.from_numpy(a)\n",
        "  a= a.type(torch.float)\n",
        "  pred=model(a)\n",
        "  print(f'Raw prediction: {pred}')\n",
        "  print(f'Model Predicted: {cls[pred.argmax()]}')\n",
        "  return\n",
        "  #  cv2_imshow(img)"
      ],
      "metadata": {
        "id": "eBwOTIW8PKwS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Load the PyTorch model which was saved using TorchScript\n",
        "* Always save PyTorch model after training using\n",
        "```\n",
        "model_scripted = torch.jit.script(model)\n",
        "model_scripted.save('model_scripted.pt')\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "jpGC6JaJOZqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.jit.load('model_scripted.pt')\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "4NxygOaHO7y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img= cv.imread('/content/download.jpg')\n",
        "img= cv.resize(img, (224, 224))\n",
        "a= img.transpose(2, 0, 1)\n",
        "a= np.expand_dims(a, 0)\n",
        "a= a/255\n",
        "a= torch.from_numpy(a)\n",
        "a= a.type(torch.float)\n",
        "pred=model(a)\n",
        "# prediction('/content/meat-steak_131550-9.avif', model)"
      ],
      "metadata": {
        "id": "y6fGC3TfP3YL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfwKza7VRJmW",
        "outputId": "835459e6-d56c-42c6-dd82-d66771545295"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6839, 0.3161]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Exporting a PyTorch model to ONNX and saving in ONNX format."
      ],
      "metadata": {
        "id": "k_prHXh_O9Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the input shape of the onnx model\n",
        "x = torch.randn(1, 3, 224, 224, requires_grad=True)\n",
        "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# x = x.to(device)"
      ],
      "metadata": {
        "id": "FaG6DvebR36B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.onnx\n",
        "torch.onnx.export(model,\n",
        "                  x,\n",
        "                  \"model.onnx\",\n",
        "                  export_params=True\n",
        "                  )"
      ],
      "metadata": {
        "id": "rw2_P6IvPSNk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Cheaking and printing the onnx model "
      ],
      "metadata": {
        "id": "4KgQHR9pSc1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# Load the ONNX model\n",
        "model = onnx.load(\"/content/model.onnx\")\n",
        "\n",
        "# Check that the model is well formed\n",
        "onnx.checker.check_model(model)\n",
        "\n",
        "# Print a human readable representation of the graph\n",
        "print(onnx.helper.printable_graph(model.graph))"
      ],
      "metadata": {
        "id": "LLuV1hgKjXLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Inferencing on the ONNX model using ONNX Runtime"
      ],
      "metadata": {
        "id": "RQTNbL-GjaDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The input for inferencing is a NumPy array and has the same data type as the model parameters."
      ],
      "metadata": {
        "id": "eyCLh3_ekfHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img= cv.imread('/content/pizza_steak/test/pizza/1179703.jpg')\n",
        "img= cv.resize(img, (224, 224))\n",
        "img= img.transpose(2, 0, 1)\n",
        "img= np.expand_dims(img, 0)\n",
        "img= img/255\n",
        "img= img.astype('float32')"
      ],
      "metadata": {
        "id": "NwxoGYJylA2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = onnxruntime.InferenceSession('/content/model.onnx')\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "print(input_name)\n",
        "print(output_name)"
      ],
      "metadata": {
        "id": "H9Fg2-asjzMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inferencing\n",
        "result = session.run([output_name], {input_name: img})\n",
        "result"
      ],
      "metadata": {
        "id": "2-Rt_PBPk5Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Converting ONNX to TFLite using OpenVINO."
      ],
      "metadata": {
        "id": "0vQhZpjUj04f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade silabs-mltk\n",
        "!pip install -q onnx onnx_tf\n",
        "!pip install -q openvino_dev\n",
        "!pip install -q onnx-simplifier onnxruntime\n",
        "!pip install -q openvino2tensorflow "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ddQxtY8mg5M",
        "outputId": "58037194-e85f-406c-850f-dd9f09065dd9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.4/222.4 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytest-dependency (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytest-html-reporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for jstyleson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "silabs-mltk 0.14.0 requires pillow<9.0, but you have pillow 9.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 KB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openvino.tools.mo import main as mo_main\n",
        "import onnx\n",
        "import onnxsim\n",
        "import onnx\n",
        "from onnx_tf.backend import prepare\n",
        "from mltk.utils.shell_cmd import run_shell_cmd\n",
        "import sys"
      ],
      "metadata": {
        "id": "XnZ0ryL2m1Go"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ONNX model\n",
        "model_path = '/content/cat_vs_dog.onnx'\n",
        "onnx_model = onnx.load(model_path)\n",
        "tf_rep = prepare(onnx_model)\n",
        "\n",
        "# Get the input tensor shape\n",
        "input_tensor = tf_rep.signatures[tf_rep.inputs[0]]\n",
        "input_shape = input_tensor.shape\n",
        "input_shape_str = '[' + ','.join([str(x) for x in input_shape]) + ']'  # it return the input shape in the string format\n"
      ],
      "metadata": {
        "id": "How_ExH9m5sO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openvino_out_dir = './openvino'\n",
        "# os.makedirs(openvino_out_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "2KNbgAEIpd8d"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f'Generating openvino at: {openvino_out_dir}')\n",
        "cmd = [ \n",
        "    sys.executable, mo_main.__file__, \n",
        "    '--input_model', model_path,\n",
        "    '--input_shape', input_shape_str,\n",
        "    '--output_dir', openvino_out_dir,\n",
        "    '--data_type', 'FP32'\n",
        "\n",
        "]\n",
        "retcode, retmsg = run_shell_cmd(cmd,  outfile=sys.stdout)\n",
        "assert retcode == 0, 'Failed to do conversion' "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psDJ0jjZplo0",
        "outputId": "c381746b-78e0-45c7-a4f7-a85c19dbf85f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ WARNING ]  Use of deprecated cli option --data_type detected. Option use in the following releases will be fatal. \n",
            "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
            "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
            "[ SUCCESS ] Generated IR version 11 model.\n",
            "[ SUCCESS ] XML file: /content/openvino22/cat_vs_dog.xml\n",
            "[ SUCCESS ] BIN file: /content/openvino22/cat_vs_dog.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openvino2tensorflow_out_dir = './openvino2tensorflow'\n",
        "openvino_xml_name = os.path.basename(model_path)[:-len('.onnx')] + '.xml'"
      ],
      "metadata": {
        "id": "xoVe_h4Hq3wS"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path= model_path + '/' + openvino_xml_name"
      ],
      "metadata": {
        "id": "EYw5stvNuGMP"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PvdoqLvPxAjz",
        "outputId": "c9041e1e-d95d-4c21-b1cf-e72a5efaae10"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/cat_vs_dog.onnx/cat_vs_dog.xml'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "from mltk.utils.shell_cmd import run_shell_cmd\n",
        "# openvino_xml_name = os.path.basename(simplified_onnx_model_path)[:-len('.onnx')] + '.xml'\n",
        "# openvinio_xml_name= 'cat_vs_dog.xml'\n",
        "\n",
        "\n",
        "if os.name == 'nt':\n",
        "  openvino2tensorflow_exe_cmd = [sys.executable, os.path.join(os.path.dirname(sys.executable), 'openvino2tensorflow')]\n",
        "else:\n",
        "  openvino2tensorflow_exe_cmd = ['openvino2tensorflow']\n",
        "\n",
        "print(f'Generating openvino2tensorflow model at: {openvino2tensorflow_out_dir} ...')\n",
        "cmd = openvino2tensorflow_exe_cmd + [ \n",
        "    '--model_path', '/content/openvino/cat_vs_dog.xml',\n",
        "    # '--model_path', path,\n",
        "    '--model_output_path', openvino2tensorflow_out_dir,\n",
        "    # '--output_saved_model',\n",
        "    '--output_no_quant_float32_tflite'\n",
        "]\n",
        "\n",
        "retcode, retmsg = run_shell_cmd(cmd)\n",
        "assert retcode == 0, retmsg\n",
        "print('done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s72aep57tvY_",
        "outputId": "76b31ea0-bfe2-4971-e8a5-63e656b0f4c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating openvino2tensorflow model at: ./openvino2tensorflow ...\n"
          ]
        }
      ]
    }
  ]
}